# 机器学习（一）贝叶斯判别式

**2018/2/13**

**by ChenjingDing**

---

符号：

$$C_k$$：第k类

p：概率密度

$$P(C_k)$$: 第k类的概率。本文中的概率密度和概率在公式推导时已严格区分。

x：输入数据：可为训练样本（已知类别）或者待分类数据（未知类别）,为变量。

$$q$$：输入数据，有固定取值，非变量

m：类型总数

---

### 一.三个基本概率

#### 1.1先验概率

根据经验得到的概率。比如$$P(C_k)$$：第k类的先验概率

#### 1.2条件概率

$$P（x|C_k）$$: 在第k类中产生观察到的数据x的概率，表示了x是由第k类产生的可能性。

#### 1.3后验概率

$$P（C_k|x）$$:输入数据x是第k类的概率。

#### 1.4 三者关系

$$p(x,C_k) = p(x|C_k)*P(C_k) = P(C_k|x)p(x)$$;

其中x是连续随机变量，注意$$P(x) = 0$$；表达式中采用的是概率密度函数。

$$C$$是离散随机变量，表达式中采用的是概率。

> 具体参考Christopher M. Bishop，Pattern Recognition and Machine Learning，Springer, 2006 1.2.1节。
>
> 在第二节4.3**生成模型和判别模型的比较**中再来比较条件概率和后验概率。

### 二.贝叶斯判别式最佳决策准测的推导

##### 目标函数：

使错分输入数据x的概率最小。

![](/assets/1.2.2.1贝叶斯判别式最小化错分概率.png)

$$图1 贝叶斯判别式最小化错分概率 $$

已知决策准测$$x_0$$, 当$$x < x_0$$，即$$x \in R_1$$，贝叶斯决策认为x属于$$C_1$$类，反之则为$$C_2$$类。

$$P（mistake）= P（x\in R_            1,C_2 ）+ P(x\in R_2,C1)\\ = \int_{R_1} p(x,C_2) dx + \int_{R_2} p(x,C_1) dx\\=\int_{R_1} P(C_2|x)*p(x) dx+ \int_{R_2} P(C_1|x)*p(x) dx$$

观察上图，当决策准测为$$\widehat{x}$$，P（mistake）是红色，绿色和蓝色的面积和。当决策准测为$$x_0$$，P（mistake）是绿色和蓝色的面积和。要使P\(mistake\)的概率最小，应使红色面积部分最小。当$$p（x,C_1）= p(x,C_2)$$时，红色部分面积为0；即分界线为$$\{ x|\ p(x,C_1)=p(x,C_2) \}$$。

##### 最佳决策准测：

贝叶斯决策将x分为$$C_1$$类：当$$P(C_1|x)*p(x) >P(C_2|x)*p(x)$$；即：$$p(x|C_1)*P(C_1) >p(x|C_2)*P(C_2)$$

$$\frac{p(x|C_1)}{p(x|C_2)} > \frac{P(C_2)}{P(C_1)}$$，其中$$\frac{P(C_2)}{P(C_1)}$$称为**决策阈值**。

### 三.损失函数在贝叶斯判别式中的的应用

#### 3.1贝叶斯决策损失函数的定义

$$L_{kj}$$（0&lt;k,j&lt;=m）: 如果x被分类到第j类，而其实x是第k类的损失值。损失矩阵就是由这些损失值构成的矩阵。

#### 3.2带损失函数的最佳决策准测

##### 3.2.1  损失函数的期望

* ##### **条件损失函数期望： **

##### $$R(a_j|q):$$对于一个特定的q输入，采取决策$$a_j$$的损失期望，也叫做条件风险。

$$R(a_j|q) = \sum_{k=1}^m L_{kj} P(C_k|q)$$

* **损失期望**

R：对于所有决策总的损失期望。

$$R = \sum_{k=1}^m \sum_{j=1}^m \int_{R_j} L_{kj} p(x,C_k) dx \\ = \sum_{j=1}^m \int_{R_j} [\sum_{k=1}^m L_{kj}P(C_k|x)]p(x) dx \\ = \sum_{j=1}^m \int_{R_j} R(a_j|x) p(x) dx \\ = E (R(a_j|q ))$$

##### 3.2.2  目标函数

对于给定输入q，选择条件风险最小的决策，可使总的损失期望最小。

以两类为例：

假设有两个类$$C_1,C_2$$，有两个决策$$a_1，a_2$$。损失函数$$L(a_j|C_k) = L_{kj}$$。

$$R(a_1|x) = L_{11}*P(C_1|x)+L_{21}P(C_2|x);$$

$$R(a_2|x)=L_{12}*P(C_1|x)+ L_{22} P(C_2|x)$$;

选择a1，如果$$R(a_2|x) > R(a_1|x) $$

$$L_{12}*P(C_1|x)+ L_{22} P(C_2|x)> L_{11}*P(C_1|x)+L_{21}P(C_2|x) \\ \frac {L_{12} - L_{11}}{L_{21} - L_{22}} > \frac{P(C_2|x)}{P(C_1|x)} = \frac{p(x|C_2)*P(C_2)}{p(x|C_1)*P(C_1)} \\ \frac{p(x|C_1)}{p(x|C_2)} > \frac {P(C_2)*(L_{21} - L_{22})}{P(C_1)*(L_{12} - L_{11})} $$

上式即为考虑损失函数的**贝叶斯最佳决策准则**。

